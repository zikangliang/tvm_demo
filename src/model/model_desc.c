/**
 * @file model_desc.c
 * @brief Model Descriptor Implementation (Compile-time generated)
 * 
 * This file contains the static description tables that would normally
 * be auto-generated by the TVM compiler. It includes:
 * - Tensor memory mapping table
 * - Operator descriptions
 * - Static BSP schedule
 * - CPU function table
 */

#include "model_desc.h"
#include <stddef.h>

// ============================================================
// Forward declarations for wrapped operators
// ============================================================
extern int32_t wrapped_fused_add(void* args);
extern int32_t wrapped_fused_add_1(void* args);
extern int32_t wrapped_fused_add_2(void* args);
extern int32_t wrapped_fused_add_3(void* args);
extern int32_t wrapped_fused_subtract(void* args);
extern int32_t wrapped_fused_subtract_1(void* args);

// ============================================================
// Tensor Memory Mapping Table
// ============================================================
// Describes where each storage id (sid) is located in workspace
// Note: sid_4 and sid_5 reuse memory from sid_1 and sid_3 respectively

static const tvmrt_tensor_map_entry_t g_tensor_map[MODEL_NUM_TENSORS] = {
    // sid, offset, size, align
    {.sid = 1, .offset = 16, .size = 4, .align = 4},  // sid_1 at ws[16]
    {.sid = 2, .offset = 0,  .size = 4, .align = 4},  // sid_2 at ws[0]
    {.sid = 3, .offset = 32, .size = 4, .align = 4},  // sid_3 at ws[32]
    {.sid = 4, .offset = 16, .size = 4, .align = 4},  // sid_4 reuses ws[16] (same as sid_1)
    {.sid = 5, .offset = 32, .size = 4, .align = 4}   // sid_5 reuses ws[32] (same as sid_3)
};

// ============================================================
// Operator Description Table
// ============================================================
// Describes each operator in the graph

static const tvmrt_op_desc_t g_op_descs[MODEL_NUM_OPS] = {
    // Node 0: fused_add(input -> sid_1)
    {
        .op_id = 0,
        .name = "fused_add_0",
        .backend = TVMRT_BACKEND_CPU,
        .func_entry_id = 0,  // wrapped_fused_add
        .input_sids = {-1, -1, -1, -1},   // input is external
        .output_sids = {1, -1},            // produces sid_1
        .input_count = 1,
        .output_count = 1
    },
    // Node 1: fused_subtract(sid_1 -> sid_2)
    {
        .op_id = 1,
        .name = "fused_subtract_0",
        .backend = TVMRT_BACKEND_CPU,
        .func_entry_id = 4,  // wrapped_fused_subtract
        .input_sids = {1, -1, -1, -1},
        .output_sids = {2, -1},
        .input_count = 1,
        .output_count = 1
    },
    // Node 2: fused_add_1(input -> sid_3)
    {
        .op_id = 2,
        .name = "fused_add_1",
        .backend = TVMRT_BACKEND_CPU,
        .func_entry_id = 1,  // wrapped_fused_add_1
        .input_sids = {-1, -1, -1, -1},
        .output_sids = {3, -1},
        .input_count = 1,
        .output_count = 1
    },
    // Node 3: fused_subtract_1(sid_3 -> sid_4)
    {
        .op_id = 3,
        .name = "fused_subtract_1",
        .backend = TVMRT_BACKEND_CPU,
        .func_entry_id = 5,  // wrapped_fused_subtract_1
        .input_sids = {3, -1, -1, -1},
        .output_sids = {4, -1},
        .input_count = 1,
        .output_count = 1
    },
    // Node 4: fused_add_2(sid_4 -> sid_5)
    {
        .op_id = 4,
        .name = "fused_add_2",
        .backend = TVMRT_BACKEND_CPU,
        .func_entry_id = 2,  // wrapped_fused_add_2
        .input_sids = {4, -1, -1, -1},
        .output_sids = {5, -1},
        .input_count = 1,
        .output_count = 1
    },
    // Node 5: fused_add_3(sid_2, sid_5 -> output)
    {
        .op_id = 5,
        .name = "fused_add_3",
        .backend = TVMRT_BACKEND_CPU,
        .func_entry_id = 3,  // wrapped_fused_add_3
        .input_sids = {2, 5, -1, -1},
        .output_sids = {-1, -1},  // output is external
        .input_count = 2,
        .output_count = 1
    }
};

// ============================================================
// CPU Function Table
// ============================================================

static const tvmrt_op_func_t g_cpu_func_table[] = {
    wrapped_fused_add,       // index 0
    wrapped_fused_add_1,     // index 1
    wrapped_fused_add_2,     // index 2
    wrapped_fused_add_3,     // index 3
    wrapped_fused_subtract,  // index 4
    wrapped_fused_subtract_1 // index 5
};

#define CPU_FUNC_COUNT (sizeof(g_cpu_func_table) / sizeof(g_cpu_func_table[0]))

// ============================================================
// Static BSP Schedule
// ============================================================

// Layer 1: Node 0, Node 2 (parallel, no dependencies)
static const int32_t g_layer1_ops[] = {0, 2};

// Layer 2: Node 1, Node 3 (parallel, depend on Layer 1)
static const int32_t g_layer2_ops[] = {1, 3};

// Layer 3: Node 4 (sequential, depends on Node 3)
static const int32_t g_layer3_ops[] = {4};

// Layer 4: Node 5 (sequential, depends on Node 1 and Node 4)
static const int32_t g_layer4_ops[] = {5};

static const tvmrt_schedule_layer_t g_schedule_layers[MODEL_NUM_LAYERS] = {
    {.op_indices = g_layer1_ops, .count = 2},
    {.op_indices = g_layer2_ops, .count = 2},
    {.op_indices = g_layer3_ops, .count = 1},
    {.op_indices = g_layer4_ops, .count = 1}
};

static const tvmrt_schedule_desc_t g_schedule = {
    .layers = g_schedule_layers,
    .layer_count = MODEL_NUM_LAYERS
};

// ============================================================
// Complete Model Descriptor
// ============================================================

static const tvmrt_model_desc_t g_model_desc = {
    .tensor_map = g_tensor_map,
    .tensor_count = MODEL_NUM_TENSORS,
    .op_descs = g_op_descs,
    .op_count = MODEL_NUM_OPS,
    .schedule = &g_schedule,
    .cpu_func_table = g_cpu_func_table,
    .cpu_func_count = CPU_FUNC_COUNT
};

// ============================================================
// Access Functions
// ============================================================

const tvmrt_model_desc_t* model_get_descriptor(void) {
    return &g_model_desc;
}

const tvmrt_tensor_map_entry_t* model_get_tensor_map(void) {
    return g_tensor_map;
}

const tvmrt_op_desc_t* model_get_op_descs(void) {
    return g_op_descs;
}

const tvmrt_schedule_desc_t* model_get_schedule(void) {
    return &g_schedule;
}

// ============================================================
// Argument Filling Helper
// ============================================================

// Storage for operator arguments (static allocation)
static FusedAddArgs g_fused_add_args[5];    // For ops 0-4
static FusedAdd3Args g_fused_add3_args;     // For op 5

int model_fill_args(
    void* args,
    float* input,
    float* output,
    uint8_t* workspace,
    const uint8_t* const_workspace
) {
    (void)args;  // We use static storage instead
    
    // Resolve SID pointers
    float* sid_1 = (float*)(workspace + 16);
    float* sid_2 = (float*)(workspace + 0);
    float* sid_3 = (float*)(workspace + 32);
    float* sid_4 = (float*)(workspace + 16);  // Reuses sid_1
    float* sid_5 = (float*)(workspace + 32);  // Reuses sid_3
    
    // Fill args for each operator
    // Node 0: fused_add(input -> sid_1)
    g_fused_add_args[0] = (FusedAddArgs){
        .p0 = input,
        .output = sid_1,
        .const_ws = (uint8_t*)const_workspace,
        .ws = workspace
    };
    
    // Node 1: fused_subtract(sid_1 -> sid_2)
    g_fused_add_args[1] = (FusedAddArgs){
        .p0 = sid_1,
        .output = sid_2,
        .const_ws = (uint8_t*)const_workspace,
        .ws = workspace
    };
    
    // Node 2: fused_add_1(input -> sid_3)
    g_fused_add_args[2] = (FusedAddArgs){
        .p0 = input,
        .output = sid_3,
        .const_ws = (uint8_t*)const_workspace,
        .ws = workspace
    };
    
    // Node 3: fused_subtract_1(sid_3 -> sid_4)
    g_fused_add_args[3] = (FusedAddArgs){
        .p0 = sid_3,
        .output = sid_4,
        .const_ws = (uint8_t*)const_workspace,
        .ws = workspace
    };
    
    // Node 4: fused_add_2(sid_4 -> sid_5)
    g_fused_add_args[4] = (FusedAddArgs){
        .p0 = sid_4,
        .output = sid_5,
        .const_ws = (uint8_t*)const_workspace,
        .ws = workspace
    };
    
    // Node 5: fused_add_3(sid_2, sid_5 -> output)
    g_fused_add3_args = (FusedAdd3Args){
        .p0 = sid_2,
        .p1 = sid_5,
        .output = output,
        .const_ws = (uint8_t*)const_workspace,
        .ws = workspace
    };
    
    return 0;
}

// ============================================================
// Get Args Pointer for Operator
// ============================================================

void* model_get_op_args(int32_t op_id) {
    if (op_id < 0 || op_id >= MODEL_NUM_OPS) {
        return NULL;
    }
    
    if (op_id < 5) {
        return &g_fused_add_args[op_id];
    } else {
        return &g_fused_add3_args;
    }
}
